Non-Autoregressive Generation Progress
======
### 2021
- [arXiv] [Non-Autoregressive Translation with Layer-Wise Prediction and Deep Supervision](https://arxiv.org/abs/2110.07515)
- [arXiv] [MvSR-NAT: Multi-view Subset Regularization for Non-Autoregressive Machine Translation](https://arxiv.org/pdf/2108.08447.pdf)
- [CL] [Sequence-Level Training for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/2106.08122.pdf)
- [EMNLP] [Exploring Non-Autoregressive Text Style Transfer](https://aclanthology.org/2021.emnlp-main.730.pdf)
- [EMNLP] [Learning to Rewrite for Non-Autoregressive Neural Machine Translation](https://aclanthology.org/2021.emnlp-main.265.pdf)
- [EMNLP] [AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate](https://aclanthology.org/2021.emnlp-main.1.pdf)
- [ICML] [Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation](https://arxiv.org/pdf/2106.05093.pdf)
- [ICML] [BANG: Bridging Autoregressive and Non-autoregressive Generation with Large Scale Pretraining](https://arxiv.org/pdf/2012.15525.pdf)
<br>A pretrained model can simultaneously support AR, NAR and semi-NAR generation ;  question generation , summarization , dialogue generation
- [ACL] [Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation](https://arxiv.org/pdf/2106.00903.pdf)
- [ACL] [Progressive Multi-Granularity Training for Non-Autoregressive Translation](https://arxiv.org/pdf/2106.05546.pdf)
- [ACL] [GLAT: Glancing Transformer for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/2008.07905.pdf)
- [ACL] [POS-Constrained Parallel Decoding for Non-autoregressive Generation](https://aclanthology.org/2021.acl-long.467.pdf)
- [ACL Findings] [Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade](https://arxiv.org/pdf/2012.15833.pdf)
- [ACL SRW] [Using Perturbed Length-aware Positional Encoding for Non-autoregressive Neural Machine Translation](https://arxiv.org/pdf/2107.13689.pdf)
- [EACL] [Enriching Non-Autoregressive Transformer with Syntactic and Semantic Structures for Neural Machine Translation](https://aclanthology.org/2021.eacl-main.105.pdf)
- [EACL] [Non-Autoregressive Text Generation with Pre-trained Language Models](https://aclanthology.org/2021.eacl-main.18.pdf)
- [NAACL] [Non-Autoregressive Semantic Parsing for Compositional Task-Oriented Dialog](https://www.aclweb.org/anthology/2021.naacl-main.236.pdf)
- [NAACL] [Non-Autoregressive Translation by Learning Target Categorical Codes](https://www.aclweb.org/anthology/2021.naacl-main.458.pdf)
- [NAACL] [Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation](https://www.aclweb.org/anthology/2021.naacl-main.313.pdf)
- [ICLR] [Understanding and Improving Lexical Choice in Non-Autoregressive Translation](https://openreview.net/pdf?id=ZTFeSBIX9C)
<br>alleviate the problem of the lexical choice errors on low-frequency words which are propagated to the NAT model from the teacher model ; Machine Translation
- [AAAI] [Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information](https://arxiv.org/pdf/1911.02215.pdf)
- [ICASSP] [Parallel tacotron: Non-autoregressive and controllable tts](https://arxiv.org/pdf/2010.11439.pdf?ref=https://githubhelp.com)
<br>a non-autoregressive neural text-to-speech model augmented with a variational autoencoder based residual encoder
### 2020
- [arXiv] [Listen and Fill in the Missing Letters: Non-Autoregressive Transformer for Speech Recognition](https://arxiv.org/pdf/1911.04908.pdf)
<br>two different non-autoregressive transformer structure for automatic speech recognition (ASR): A-CMLM and A-FMLM.
- [arXiv] [Non-Autoregressive Neural Dialogue Generation](https://arxiv.org/pdf/2002.04250.pdf)
- [arXiv] [Improving Fluency of Non-Autoregressive Machine Translation](https://arxiv.org/pdf/2004.03227.pdf)
- [arXiv] [Semi-Autoregressive Training Improves Mask-Predict Decoding](https://arxiv.org/pdf/2001.08785.pdf)
- [arXiv] [LAVA NAT: A Non-Autoregressive Translation Model with Look-Around Decoding and Vocabulary Attention](https://arxiv.org/pdf/2002.03084.pdf)
- [IJCAI] [Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/2007.08772.pdf)
- [COLING] [Context-Aware Cross-Attention for Non-Autoregressive Translation](https://arxiv.org/abs/2011.00770)
- [COLING] [Infusing Sequential Information into Conditional Masked Translation Model with Self-Review Mechanism](https://aclanthology.org/2020.coling-main.2.pdf)
- [NeurIPS] [Incorporating BERT into Parallel Sequence Decoding with Adapters](https://arxiv.org/pdf/2010.06138.pdf)
- [EMNLP] [Non-Autoregressive Machine Translation with Latent Alignments](https://arxiv.org/pdf/2004.07437.pdf)
- [EMNLP] [Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/2009.07177.pdf)
- [EMNLP] [SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection and Slot Filling](https://www.aclweb.org/anthology/2020.emnlp-main.152.pdf)
- [INTERSPEECH] [Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict](https://arxiv.org/pdf/2005.08700.pdf)
- [INTERSPEECH] [Insertion-Based Modeling for End-to-End Automatic Speech Recognition](https://arxiv.org/pdf/2005.13211.pdf)
- [ACL] [Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation](https://www.aclweb.org/anthology/2020.acl-main.277.pdf)
- [ACL] [Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation](https://www.aclweb.org/anthology/2020.acl-main.36.pdf)
- [ACL] [ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation](https://www.aclweb.org/anthology/2020.acl-main.251.pdf)
- [ACL] [Improving Non-autoregressive Neural Machine Translation with Monolingual Data](https://www.aclweb.org/anthology/2020.acl-main.171.pdf)
- [ACL] [A Study of Non-autoregressive Model for Sequence Generation](https://www.aclweb.org/anthology/2020.acl-main.15.pdf)
<br>a study to understand the difficulty of NAR sequence generation
- [ICML] [Non-Autoregressive Neural Text-to-Speech](https://arxiv.org/pdf/1905.08459.pdf)
<br> a non-autoregressive seq2seq model that converts text to speech
- [ICML] [Aligned Cross Entropy for Non-Autoregressive Machine Translation](https://arxiv.org/pdf/2004.01655.pdf)
<br>propose aligned cross entropy (AXE) as an alternative loss function for training of non-autoregressive models ; Machine Translation
- [ICML] [Parallel Machine Translation with Disentangled Context Transformer](https://arxiv.org/pdf/2001.05136.pdf)
- [ICML] [Imputer: Sequence Modelling via Imputation and Dynamic Programming](https://arxiv.org/pdf/2002.08926.pdf)
- [ICML] [An EM Approach to Non-autoregressive Conditional Sequence Generation](https://arxiv.org/pdf/2006.16378.pdf)
- [ICLR] [Understanding Knowledge Distillation in Non-autoregressive Machine Translation](https://arxiv.org/pdf/1911.02727.pdf)
- [AAAI] [Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/1911.09320.pdf)
- [AAAI] [Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior](https://arxiv.org/pdf/1908.07181.pdf)
<br>a latent-variable non-autoregressive model with continuous latent variables and deterministic inference procedure Using a Delta Posterior ; Machine Translation
- [AAAI] [Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/1911.08717.pdf)
<br>design a curriculum in the fine-tuning process to progressively switch the training from autoregressive generation to non-autoregressive generation ; Machine Translation

### 2019
- [PMLR] [Insertion Transformer:flexible sequence generation via insertion operations](http://proceedings.mlr.press/v97/stern19a/stern19a.pdf)
<br>an iterative, partially autoregressive model for sequence generation based on insertion operations ; machine translation
- [arXiv] [Non-autoregressive Transformer by Position Learning](https://arxiv.org/pdf/1911.10677.pdf)
<br>a non-autoregressive model which incorporates positions as a latent variable into the text generative process ; machine translation , paraphrase generation
- [NeurIPS] [Levenshtein Transformer](https://papers.nips.cc/paper/9297-levenshtein-transformer.pdf)
<br>a non-autoregressive model whose the basic operations are insertion and deletion ; machine translation, text summarization , automatic post-editing
- [NeurIPS] [Fast Structured Decoding for Sequence Models](https://arxiv.org/pdf/1910.11555.pdf)
<br>design an efficient approximation for Conditional Random Fields (CRF) for non-autoregressive sequence models ; Machine Translation
- [NeurIPS] [FastSpeech: Fast, Robust and Controllable Text to Speech](https://arxiv.org/pdf/1905.09263.pdf)
<br> a novel feed-forward network based on Transformer to generate mel-spectrogram in parallel for TTS ; text to speech
- [EMNLP] [Mask-Predict: Parallel Decoding of Conditional Masked Language Models](https://arxiv.org/pdf/1904.09324.pdf)
<br>first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words ; Machine Translation
- [EMNLP] [FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow](https://arxiv.org/pdf/1909.02480.pdf)
<br>a non-autoregressive sequence generation using latent variable models ; Machine Translation
- [EMNLP] [Hint-Based Training for Non-Autoregressive Machine Translation](https://www.aclweb.org/anthology/D19-1573.pdf)
<br>proposed a novel approach to leveraging the hints from hidden states and word alignments to help the training of NART models ; Machine Translation
- [ACL] [Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/1906.09444.pdf)
<br>propose a sequence-level training method based on a novel reinforcement algorithm to reduce the variance and stabilize the training procedure and an innovative Transformer
decoder named FS-decoder to fuse the target sequential information into the top layer of the decoder ; Machine Translation
- [ACL] [Imitation Learning for Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/1906.02041.pdf)
<br>an imitation learning framework for non-autoregressive machine translation
- [AAAI] [Non-Autoregressive Machine Translation with Auxiliary Regularization](https://arxiv.org/pdf/1902.10245.pdf)
<br>address repeated translations and incomplete translations by improving the quality of decoder hidden representations via two auxiliary regularization terms in the training process of an NAT model ; Machine Translation
- [AAAI] [Non-Autoregressive Neural Machine Translation with Enhanced Decoder Input](https://arxiv.org/pdf/1812.09664.pdf)
<br>two methods to enhance the decoder inputs so as to improve NAT models ; Machine Translation

### 2018
- [ICML] [Fast Decoding in Sequence Models Using Discrete Latent Variables](https://arxiv.org/pdf/1803.03382.pdf)
<br>first autoencode the target sequence into a shorter sequence of discrete latent variables autoregressively and finally decode the output sequence from this shorter latent
sequence in parallel ; Machine Translation
- [EMNLP] [Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement](https://arxiv.org/pdf/1802.06901.pdf)
<br>a conditional non-autoregressive neural sequence model based on iterative refinement ; machine translation , image caption generation
- [EMNLP] [End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification](https://arxiv.org/pdf/1811.04719.pdf)
<br>a novel non-autoregressive architecture based on connectionist temporal classification and can be trained end-to-end ; Machine Translation
- [ICLR] [Non-Autoregressive Neural Machine Translation](https://arxiv.org/pdf/1711.02281.pdf)
<br>Machine Translation

# Contact
Changhan Wang ([wangchanghan@gmail.com](mailto:wangchanghan@gmail.com))



新增
### 2021
- [] []()
- [AAAI] [Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences.](https://ojs.aaai.org/index.php/AAAI/article/view/17552/17359)
- [ACL findings] [A Non-Autoregressive Edit-Based Approach to Controllable Text Simplification](https://aclanthology.org/2021.findings-acl.330.pdf)
- [ACL findings] [Investigating the Reordering Capability in CTC-based Non-Autoregressive End-to-End Speech Translation](https://aclanthology.org/2021.findings-acl.92.pdf)
- [ACL findings] [NAST: A Non-Autoregressive Generator with Word Alignment for Unsupervised Text Style Transfer.](https://aclanthology.org/2021.findings-acl.138.pdf)
- [ACL] [Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese Grammatical Error Correction. ](https://aclanthology.org/2021.acl-long.385.pdf)
- [ACL] [How Does Distilled Data Complexity Impact the Quality and Confidence of Non-Autoregressive Machine Translation?](https://arxiv.org/pdf/2105.12900v1.pdf)
- [EMNLP] [Maximal Clique Based Non-Autoregressive Open Information Extraction](https://aclanthology.org/2021.emnlp-main.764.pdf)
- [EMNLP findings] [Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic Parsing](https://aclanthology.org/2021.findings-emnlp.161.pdf)
- [EMNLP] [Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems](https://aclanthology.org/2021.emnlp-main.169.pdf)
- [ICASSP] [CASS-NAT: CTC Alignment-Based Single Step Non-Autoregressive Transformer for Speech Recognition](https://arxiv.org/pdf/2010.14725v2.pdf)
- [ICASSP] [Non-Autoregressive Sequence-To-Sequence Voice Conversion](https://arxiv.org/pdf/2104.06793)
- [ICASSP] [Improved Mask-CTC for Non-Autoregressive End-to-End ASR](https://arxiv.org/pdf/2010.13270.pdf?ref=https://githubhelp.com)
- [ICASSP] [ORTHROS: non-autoregressive end-to-end speech translation With dual-decoder](https://arxiv.org/pdf/2010.13047)
- [ICASSP] [Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input](https://arxiv.org/pdf/2010.15025)
- [ICLR] [Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation](https://openreview.net/pdf?id=KpfasTaLUpq)
- [ICLR] [Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech](https://openreview.net/pdf?id=o3iritJHLfO)
- [NAACL] [Align-Refine: Non-Autoregressive Speech Recognition via Iterative Realignment](https://aclanthology.org/2021.naacl-main.154.pdf)
- [] []()
